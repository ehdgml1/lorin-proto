"""
LORIN Streamlit UI
ë¡œì»¬í˜¸ìŠ¤íŠ¸ ì „ìš© ê°„ë‹¨í•œ UI
"""

import streamlit as st
import asyncio
from pathlib import Path
import sys
import pandas as pd
import os
import tempfile
import shutil
import atexit
import signal
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend for Streamlit

# LORIN ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent))

# ì´ìƒ íƒì§€ ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€ (lorin-proto ë‚´ë¶€ì˜ stage1_filtering ë””ë ‰í„°ë¦¬)
# ë‹¨, parse_logì™€ì˜ ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´ ë‚˜ì¤‘ì— ì¶”ê°€
LORIN_PROTO_DIR = Path(__file__).parent.parent.parent
STAGE1_FILTERING_DIR = LORIN_PROTO_DIR / "stage1_filtering"

# ì¢…ë£Œ ì‹œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜
def cleanup_gpu_on_exit():
    """í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
    try:
        import torch
        import gc
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
            print("ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ)")
    except Exception as e:
        print(f"GPU ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ì¢…ë£Œ í•¸ë“¤ëŸ¬ ë“±ë¡ (atexitë§Œ ì‚¬ìš© - Streamlit í˜¸í™˜)
atexit.register(cleanup_gpu_on_exit)

# Signal í•¸ë“¤ëŸ¬ëŠ” ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œë§Œ ì‘ë™í•˜ë¯€ë¡œ ì¡°ê±´ë¶€ë¡œ ë“±ë¡
try:
    def signal_handler(sig, frame):
        """Ctrl+C ì‹œê·¸ë„ ì²˜ë¦¬"""
        print("\nğŸ›‘ ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹  - GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
        cleanup_gpu_on_exit()
        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
except ValueError:
    # Streamlitì—ì„œëŠ” signalì´ ë©”ì¸ ìŠ¤ë ˆë“œê°€ ì•„ë‹ˆë¯€ë¡œ ë¬´ì‹œ
    pass

# GPU í™˜ê²½ ì„¤ì • (build_all_faiss_indexes.py íŒ¨í„´)
def setup_gpu_environment():
    """PyTorch GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”"""
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

    try:
        import torch
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
    except Exception as e:
        print(f"GPU í™˜ê²½ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")

# ì•± ì‹œì‘ ì‹œ GPU í™˜ê²½ ìµœì í™”
setup_gpu_environment()

from LORIN.agent.state import create_initial_state, get_last_message
from LORIN.agent.graph import create_agent_graph
from LORIN.process.route import initialize_graph
from main import build_vectorstore
from LORIN.utils import create_chatbot_from_env
# LORIN/ui/parse_log.pyë¥¼ ëª…ì‹œì ìœ¼ë¡œ import (stage1_filtering/parse_log.pyì™€ êµ¬ë¶„)
# ìƒëŒ€ importë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…ì‹œì ìœ¼ë¡œ LORIN.ui.parse_logë¥¼ import
from LORIN.ui import parse_log as ui_parse_log
parse_text = ui_parse_log.parse_text
parse_text_to_csv_files = ui_parse_log.parse_text_to_csv_files
from io import StringIO
from contextlib import redirect_stdout
from types import SimpleNamespace

# ì´ìƒ íƒì§€ ëª¨ë“ˆ import (lorin-proto ë‚´ë¶€ì˜ stage1_filtering ë””ë ‰í„°ë¦¬ì—ì„œ)
# test.pyê°€ models.modelì„ importí•˜ê¸° ì „ì— stage1_filtering ë””ë ‰í„°ë¦¬ë¥¼ sys.pathì— ì¶”ê°€í•´ì•¼ í•¨
ANOMALY_DETECTION_AVAILABLE = False
ANOMALY_DETECTION_ERROR = None
ANOMALY_DETECTION_ERROR_TRACEBACK = None
try:
    # test.py ë‚´ë¶€ì—ì„œ SCRIPT_DIR.parentë¥¼ sys.pathì— ì¶”ê°€í•˜ì§€ë§Œ,
    # import ì‹œì—ëŠ” ì‹¤í–‰ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¯¸ë¦¬ ì¶”ê°€
    # parse_log ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´ ë‚˜ì¤‘ì— ì¶”ê°€
    if str(STAGE1_FILTERING_DIR) not in sys.path:
        sys.path.insert(0, str(STAGE1_FILTERING_DIR))

    from stage1_filtering.scripts.test import (
        build_dual_branch_and_save,
        infer_ensemble_unlabeled_and_label_rows,
    )
    ANOMALY_DETECTION_AVAILABLE = True
except ImportError as e:
    ANOMALY_DETECTION_ERROR = str(e)
    import traceback
    ANOMALY_DETECTION_ERROR_TRACEBACK = traceback.format_exc()
except Exception as e:
    ANOMALY_DETECTION_ERROR = str(e)
    import traceback
    ANOMALY_DETECTION_ERROR_TRACEBACK = traceback.format_exc()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="LORIN Log Analyzer",
    page_icon="ğŸ”",
    layout="wide"
)

# í™”ë©´ ë°°ê²½ í•˜ì–€ìƒ‰ìœ¼ë¡œ ì„¤ì • + ìš”ì†Œë“¤ ì–´ë‘ìš´ ìƒ‰ìœ¼ë¡œ
st.markdown("""
    <style>
    /* ë°°ê²½ */
    .stApp {
        background-color: white;
    }
    [data-testid="stAppViewContainer"] {
        background-color: white;
    }
    [data-testid="stHeader"] {
        background-color: white;
    }
    [data-testid="stSidebar"] {
        background-color: #f8f9fa;
    }

    /* í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    .stApp, .stMarkdown, p, span, label {
        color: #1a1a1a !important;
    }

    /* í—¤ë” í…ìŠ¤íŠ¸ */
    h1, h2, h3, h4, h5, h6 {
        color: #000000 !important;
    }

    /* ë²„íŠ¼ - ë¶€ë“œëŸ¬ìš´ í¬ë¦¼ ë² ì´ì§€ ê³„ì—´ */
    .stButton > button {
        background-color: #fceacd;
        color: #333333 !important;
        border: 2px solid #f5dbb8;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        background-color: #f5dbb8;
        border-color: #eecca3;
        transform: translateY(-1px);
        box-shadow: 0 4px 8px rgba(252, 234, 205, 0.3);
    }
    /* Primary ë²„íŠ¼ (type="primary") */
    .stButton > button[kind="primary"] {
        background-color: #fceacd;
        border-color: #f5dbb8;
        color: #333333 !important;
    }
    .stButton > button[kind="primary"]:hover {
        background-color: #f5dbb8;
        border-color: #eecca3;
    }

    /* ì…ë ¥ì°½ */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea {
        background-color: #f8f9fa;
        color: #1a1a1a !important;
        border: 2px solid #dee2e6;
    }

    /* ì„ íƒë°•ìŠ¤ */
    .stSelectbox > div > div {
        background-color: #f8f9fa;
        color: #1a1a1a !important;
        border: 2px solid #dee2e6;
    }

    /* ì²´í¬ë°•ìŠ¤ */
    .stCheckbox > label {
        color: #1a1a1a !important;
    }

    /* Expander */
    .streamlit-expanderHeader {
        background-color: #e9ecef;
        color: #1a1a1a !important;
        font-weight: 600;
    }

    /* ê²½ê³ /ì„±ê³µ/ì—ëŸ¬ ë©”ì‹œì§€ */
    .stAlert {
        color: #1a1a1a !important;
    }

    /* ì½”ë“œ ë¸”ë¡ */
    code {
        background-color: #f8f9fa;
        color: #c7254e;
        border: 1px solid #dee2e6;
    }

    /* íŒŒì¼ ì—…ë¡œë” */
    [data-testid="stFileUploader"] {
        background-color: #e8f4f8;
        border: 2px dashed #3498db;
        border-radius: 8px;
        padding: 20px;
    }
    [data-testid="stFileUploader"] label {
        color: #2c3e50 !important;
        font-weight: 600;
        font-size: 16px;
    }
    [data-testid="stFileUploader"] section {
        border: none;
    }
    [data-testid="stFileUploader"] section > div {
        color: #2c3e50 !important;
        font-weight: 500;
        font-size: 14px;
    }
    /* Drag and drop í…ìŠ¤íŠ¸ */
    [data-testid="stFileUploader"] small {
        color: #2c3e50 !important;
        font-weight: 500;
    }
    [data-testid="stFileUploader"] p {
        color: #2c3e50 !important;
    }
    /* ì—…ë¡œë“œ ë²„íŠ¼ */
    [data-testid="stFileUploader"] button {
        background-color: #3498db;
        color: white !important;
        border: none;
        border-radius: 4px;
        font-weight: 600;
    }
    [data-testid="stFileUploader"] button:hover {
        background-color: #2980b9;
    }

    /* ë¶„ì„ ì¤‘ ì• ë‹ˆë©”ì´ì…˜ */
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    .analyzing-emoji {
        display: inline-block;
        animation: spin 2s linear infinite;
        font-size: 1.2em;
        margin-right: 8px;
    }
    .progress-text {
        font-weight: 600;
        color: #2c3e50;
    }
    </style>
    """, unsafe_allow_html=True)

# ì„ë² ë”© ëª¨ë¸ ìºì‹± (build_all_faiss_indexes.py íŒ¨í„´)
@st.cache_resource
def get_embeddings_model(batch_size: int = 8):
    """
    ì„ë² ë”© ëª¨ë¸ì„ ìºì‹±í•˜ì—¬ ì¬ì‚¬ìš© (build_all_faiss_indexes.py íŒ¨í„´)

    Args:
        batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 8 - balanced mode)

    Returns:
        BGEGemma2MultiGPUEmbeddings: ìºì‹±ëœ ì„ë² ë”© ëª¨ë¸
    """
    from LORIN.make_faiss.make_faiss_with_bge_multilingual_gemma2 import (
        BGEGemma2MultiGPUEmbeddings
    )

    st.info(f"ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘ (batch_size={batch_size})...")
    embeddings = BGEGemma2MultiGPUEmbeddings(
        model_name="BAAI/bge-multilingual-gemma2",
        use_multi_gpu=False,
        batch_size_per_gpu=batch_size,
        use_fp16=True
    )
    st.success("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ìºì‹±ë¨)")
    return embeddings

# DataFrameì—ì„œ FAISS ì¸ë±ìŠ¤ ë¹Œë“œ í•¨ìˆ˜
def build_faiss_from_df(df: pd.DataFrame, output_dir: Path):
    """
    DataFrameìœ¼ë¡œë¶€í„° FAISS ì¸ë±ìŠ¤ ë¹Œë“œ

    Args:
        df: êµ¬ì¡°í™”ëœ ë¡œê·¸ DataFrame
        output_dir: ì¸ë±ìŠ¤ ì €ì¥ ë””ë ‰í† ë¦¬

    Returns:
        str: ë¹Œë“œëœ ì¸ë±ìŠ¤ ê²½ë¡œ
    """
    import torch
    import gc
    from LORIN.make_faiss.make_faiss_with_bge_multilingual_gemma2 import build_docs_from_df
    from langchain_community.vectorstores import FAISS

    # ë¬¸ì„œ ìƒì„±
    try:
        with st.spinner("ğŸ“„ ë¬¸ì„œ ì²­í¬ ìƒì„± ì¤‘..."):
            docs = build_docs_from_df(df)
            st.success(f"âœ… {len(docs):,} ë¬¸ì„œ ì²­í¬ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

    # ìºì‹±ëœ ì„ë² ë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (build_all_faiss_indexes.py íŒ¨í„´)
    embeddings = get_embeddings_model(batch_size=4)

    # FAISS ì¸ë±ìŠ¤ ë¹Œë“œ (build_single_index íŒ¨í„´)
    try:
        with st.spinner("ğŸ”¨ FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì¤‘..."):
            vectorstore = FAISS.from_documents(docs, embeddings)

            # ì¸ë±ìŠ¤ ì €ì¥
            output_dir.mkdir(parents=True, exist_ok=True)
            vectorstore.save_local(str(output_dir))

            # íŒŒì¼ í¬ê¸° í™•ì¸
            faiss_file = output_dir / "index.faiss"
            faiss_size = faiss_file.stat().st_size / (1024**2) if faiss_file.exists() else 0
            st.success(f"âœ… FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì™„ë£Œ ({faiss_size:.1f} MB)")

    except torch.cuda.OutOfMemoryError as e:
        st.error(f"âŒ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì‹¤íŒ¨: {e}")
        return None
    finally:
        # ëª…ì‹œì  ë©”ëª¨ë¦¬ í•´ì œ (build_single_index íŒ¨í„´)
        if 'vectorstore' in locals():
            del vectorstore
        if 'docs' in locals():
            del docs

        # ì™„ì „í•œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.synchronize()  # GPU ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
            torch.cuda.empty_cache()   # GPU ìºì‹œ ë¹„ìš°ê¸°
            gc.collect()               # Python GC ì‹¤í–‰

    return str(output_dir)

# TXT íŒŒì¼ ì—…ë¡œë“œ ë° FAISS ì¸ë±ìŠ¤ ë¹Œë“œ í•¨ìˆ˜ (ë ˆê±°ì‹œ - í˜¸í™˜ì„± ìœ ì§€)
def build_faiss_from_txt(txt_file, output_dir: Path):
    """
    ì—…ë¡œë“œëœ TXT ë¡œê·¸ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ FAISS ì¸ë±ìŠ¤ ë¹Œë“œ

    Args:
        txt_file: Streamlit UploadedFile ê°ì²´ (TXT íŒŒì¼)
        output_dir: ì¸ë±ìŠ¤ ì €ì¥ ë””ë ‰í† ë¦¬

    Returns:
        str: ë¹Œë“œëœ ì¸ë±ìŠ¤ ê²½ë¡œ
    """
    import torch
    import gc
    from LORIN.make_faiss.make_faiss_with_bge_multilingual_gemma2 import build_docs_from_df
    from langchain_community.vectorstores import FAISS

    # TXT íŒŒì¼ ì½ê¸° ë° íŒŒì‹±
    try:
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        bytes_data = txt_file.read()
        try:
            text = bytes_data.decode("utf-8")
        except UnicodeDecodeError:
            text = bytes_data.decode("utf-8", errors="ignore")
        
        st.info(f"ğŸ“„ TXT íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(text.splitlines()):,} lines")
        
        # í…ìŠ¤íŠ¸ íŒŒì‹±
        with st.spinner("ğŸ“ ë¡œê·¸ íŒŒì¼ íŒŒì‹± ì¤‘..."):
            df = parse_text(text)
        st.info(f"ğŸ“Š íŒŒì‹± ì™„ë£Œ: {len(df):,} rows")
    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ë¡œë“œ/íŒŒì‹± ì‹¤íŒ¨: {e}")
        import traceback
        with st.expander("ìƒì„¸ ì˜¤ë¥˜"):
            st.code(traceback.format_exc())
        return None

    # ë¬¸ì„œ ìƒì„±
    try:
        with st.spinner("ğŸ“„ ë¬¸ì„œ ì²­í¬ ìƒì„± ì¤‘..."):
            docs = build_docs_from_df(df)
            st.success(f"âœ… {len(docs):,} ë¬¸ì„œ ì²­í¬ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

    # ìºì‹±ëœ ì„ë² ë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (build_all_faiss_indexes.py íŒ¨í„´)
    embeddings = get_embeddings_model(batch_size=4)

    # FAISS ì¸ë±ìŠ¤ ë¹Œë“œ (build_single_index íŒ¨í„´)
    try:
        with st.spinner("ğŸ”¨ FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì¤‘..."):
            vectorstore = FAISS.from_documents(docs, embeddings)

            # ì¸ë±ìŠ¤ ì €ì¥
            output_dir.mkdir(parents=True, exist_ok=True)
            vectorstore.save_local(str(output_dir))

            # íŒŒì¼ í¬ê¸° í™•ì¸
            faiss_file = output_dir / "index.faiss"
            faiss_size = faiss_file.stat().st_size / (1024**2) if faiss_file.exists() else 0
            st.success(f"âœ… FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì™„ë£Œ ({faiss_size:.1f} MB)")

    except torch.cuda.OutOfMemoryError as e:
        st.error(f"âŒ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì‹¤íŒ¨: {e}")
        return None
    finally:
        # ëª…ì‹œì  ë©”ëª¨ë¦¬ í•´ì œ (build_single_index íŒ¨í„´)
        if 'vectorstore' in locals():
            del vectorstore
        if 'docs' in locals():
            del docs
        if 'df' in locals():
            del df
        # embeddingsëŠ” ìºì‹±ëœ ëª¨ë¸ì´ë¯€ë¡œ ì‚­ì œí•˜ì§€ ì•ŠìŒ!

        # ì™„ì „í•œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.synchronize()  # GPU ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
            torch.cuda.empty_cache()   # GPU ìºì‹œ ë¹„ìš°ê¸°
            gc.collect()               # Python GC ì‹¤í–‰

    return str(output_dir)

# ì‹±ê¸€í„´ ì´ˆê¸°í™” (Streamlit cache í™œìš©)
@st.cache_resource
def initialize_analyzer(index_path: str):
    """ì¸ë±ìŠ¤ ê²½ë¡œê°€ ì œê³µëœ ê²½ìš°ì—ë§Œ ì´ˆê¸°í™”

    Args:
        index_path: FAISS ì¸ë±ìŠ¤ ê²½ë¡œ (í•„ìˆ˜)
    """
    with st.spinner("ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
        # ì»¤ìŠ¤í…€ ì¸ë±ìŠ¤ ê²½ë¡œ ì„¤ì •
        os.environ["FAISS_INDEX_PATH"] = index_path

        vectorstore, _ = build_vectorstore()

        # Chatbot
        chatbot = create_chatbot_from_env(temperature=0.4)

        # Graph ìƒì„± ë° ì»´íŒŒì¼
        graph = create_agent_graph()
        graph = asyncio.run(initialize_graph(graph, chatbot, vectorstore))
        compiled_graph = graph.compile()

        return compiled_graph, chatbot, vectorstore

# ì‹œê°í™” í•¨ìˆ˜
def create_visualization(csv_path: str) -> str:
    """
    ì—…ë¡œë“œëœ CSVë¡œ ì‹œê°í™” ìƒì„±

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ

    Returns:
        str: ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    """
    sys.path.append(str(Path(__file__).parent.parent / "log_data"))
    from visualize_logs_v6_final import create_v6_final_dashboard

    # ì„ì‹œ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    output_path = Path(tempfile.gettempdir()) / f"lorin_viz_{os.getpid()}.png"

    # ì‹œê°í™” ìƒì„±
    create_v6_final_dashboard(csv_path, output_path=str(output_path))

    return str(output_path)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "custom_index_path" not in st.session_state:
    st.session_state.custom_index_path = None
if "system_initialized" not in st.session_state:
    st.session_state.system_initialized = False
if "uploaded_csv_path" not in st.session_state:
    st.session_state.uploaded_csv_path = None
if "anomaly_detection_enabled" not in st.session_state:
    st.session_state.anomaly_detection_enabled = True
# ì´ìƒ íƒì§€ íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (lorin-proto ë‚´ë¶€ì˜ stage1_filtering ë””ë ‰í„°ë¦¬ ê¸°ì¤€)
DEFAULT_TEACHER_CKPT = STAGE1_FILTERING_DIR / "teacher_pretrained_aosp.pt"
DEFAULT_STUDENT_ROOT = STAGE1_FILTERING_DIR / "revkd_out_v5_aosp"
DEFAULT_SEEDS = "42,77,99"
DEFAULT_CKPTS = "best"

if "pipeline_teacher_ckpt" not in st.session_state:
    st.session_state.pipeline_teacher_ckpt = str(DEFAULT_TEACHER_CKPT)
if "pipeline_student_root" not in st.session_state:
    st.session_state.pipeline_student_root = str(DEFAULT_STUDENT_ROOT)
if "pipeline_student_ckpt_files" not in st.session_state:
    st.session_state.pipeline_student_ckpt_files = ""
if "pipeline_seeds" not in st.session_state:
    st.session_state.pipeline_seeds = DEFAULT_SEEDS
if "pipeline_ckpts" not in st.session_state:
    st.session_state.pipeline_ckpts = DEFAULT_CKPTS

# ì¡°ê±´ë¶€ ì´ˆê¸°í™” (ì¸ë±ìŠ¤ê°€ ìˆì„ ë•Œë§Œ)
if st.session_state.custom_index_path:
    compiled_graph, chatbot, vectorstore = initialize_analyzer(st.session_state.custom_index_path)
    st.session_state.system_initialized = True
else:
    compiled_graph, chatbot, vectorstore = None, None, None
    st.session_state.system_initialized = False

# UI í—¤ë”
st.title("ğŸ” LORIN Log Analyzer")
st.markdown("ë©€í‹°ì—ì´ì „íŠ¸ ê¸°ë°˜ ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°” - ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # TXT íŒŒì¼ ì—…ë¡œë“œ ë° FAISS ì¸ë±ìŠ¤ ë¹Œë“œ (ìµœìƒë‹¨ì— ë°°ì¹˜)
    st.subheader("ğŸ“‚ TXT ì›ë³¸ íŒŒì¼ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader(
        "ë¡œê·¸ TXT íŒŒì¼ ì—…ë¡œë“œ",
        type=["txt", "log"],
        help="TXT ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ íŒŒì‹± í›„ FAISS ì¸ë±ìŠ¤ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤"
    )

    # ì´ìƒ íƒì§€ ì„¤ì • - ìë™ìœ¼ë¡œ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•˜ì§€ ì•ŠìŒ)
    if not ANOMALY_DETECTION_AVAILABLE:
        st.error("âŒ ì´ìƒ íƒì§€ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. stage1_filtering ëª¨ë“ˆì„ í™•ì¸í•˜ì„¸ìš”.")
        st.info(f"ğŸ’¡ lorin-proto ë””ë ‰í„°ë¦¬ ê²½ë¡œ: {LORIN_PROTO_DIR}")
        st.info(f"ğŸ’¡ stage1_filtering ë””ë ‰í„°ë¦¬ ê²½ë¡œ: {STAGE1_FILTERING_DIR}")
        st.info(f"ğŸ’¡ stage1_filtering ë””ë ‰í„°ë¦¬ ì¡´ì¬ ì—¬ë¶€: {STAGE1_FILTERING_DIR.exists()}")
        if ANOMALY_DETECTION_ERROR:
            st.error(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {ANOMALY_DETECTION_ERROR}")
            if ANOMALY_DETECTION_ERROR_TRACEBACK:
                with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                    st.code(ANOMALY_DETECTION_ERROR_TRACEBACK)
        st.stop()
    
    # ìë™ìœ¼ë¡œ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì ì…ë ¥ ë¶ˆí•„ìš”, UIì— í‘œì‹œí•˜ì§€ ì•ŠìŒ)
    teacher_ckpt = str(DEFAULT_TEACHER_CKPT)
    student_root = str(DEFAULT_STUDENT_ROOT)
    student_ckpt_files = ""
    seeds = DEFAULT_SEEDS
    ckpts = DEFAULT_CKPTS

    if uploaded_file is not None:
        if st.button("ğŸ”¨ FAISS ì¸ë±ìŠ¤ ë¹Œë“œ & ì ìš©", type="primary"):
            try:
                # TXT íŒŒì¼ ì½ê¸°
                uploaded_file.seek(0)
                bytes_data = uploaded_file.read()
                try:
                    text = bytes_data.decode("utf-8")
                except UnicodeDecodeError:
                    text = bytes_data.decode("utf-8", errors="ignore")
                
                # ì„ì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
                temp_base_dir = Path(tempfile.gettempdir()) / f"lorin_{uploaded_file.name.replace('.txt', '').replace('.log', '')}"
                temp_base_dir.mkdir(parents=True, exist_ok=True)
                
                # 1ë‹¨ê³„: íŒŒì‹±í•˜ì—¬ structured.csvì™€ templates.csv ìƒì„±
                with st.spinner("ğŸ“ ë¡œê·¸ íŒŒì¼ íŒŒì‹± ì¤‘..."):
                    structured_csv, templates_csv = parse_text_to_csv_files(text, temp_base_dir)
                    st.success(f"âœ… íŒŒì‹± ì™„ë£Œ: {structured_csv.name}, {templates_csv.name}")
                
                # 2ë‹¨ê³„: ì´ìƒ íƒì§€ ìˆ˜í–‰ (í•„ìˆ˜)
                if not ANOMALY_DETECTION_AVAILABLE:
                    st.error("âŒ ì´ìƒ íƒì§€ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. stage1_filtering ëª¨ë“ˆì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.stop()
                
                # ì´ìƒ íƒì§€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                anomaly_out_dir = temp_base_dir / "anomaly_detection"
                anomaly_out_dir.mkdir(parents=True, exist_ok=True)
                
                # ì„¤ì • ê²€ì¦
                errors = []
                if not teacher_ckpt.strip():
                    errors.append("êµì‚¬ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                elif not Path(teacher_ckpt).exists():
                    errors.append(f"êµì‚¬ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {teacher_ckpt}")
                
                if student_root.strip() and not Path(student_root).exists():
                    errors.append(f"í•™ìƒ ëª¨ë¸ ë£¨íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {student_root}")
                
                if errors:
                    for msg in errors:
                        st.error(msg)
                    st.stop()
                
                # ì´ìƒ íƒì§€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                with st.spinner("ğŸ” ì´ìƒ íƒì§€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘..."):
                    args = SimpleNamespace(
                        struct_csv=structured_csv,
                        template_csv=templates_csv,
                        out=anomaly_out_dir,
                        embed_model="sentence-transformers/all-mpnet-base-v2",
                        sbert_batch=64,
                        window_size=50,
                        stride=50,
                        teacher_ckpt=Path(teacher_ckpt),
                        batch=192,
                        student_root=Path(student_root) if student_root.strip() else None,
                        student_ckpt_files=student_ckpt_files,
                        seeds=seeds,
                        ckpts=ckpts,
                    )
                    
                    log_buffer = StringIO()
                    try:
                        with redirect_stdout(log_buffer):
                            N_dedup, orig_to_dedup_idx, win_starts = build_dual_branch_and_save(args)
                            infer_ensemble_unlabeled_and_label_rows(args, N_dedup, orig_to_dedup_idx, win_starts)
                        
                        # ê²°ê³¼ CSV ê²½ë¡œ
                        labeled_csv = anomaly_out_dir / "Android.log_structured_clean.labeled.csv"
                        if not labeled_csv.exists():
                            st.error("âŒ ì´ìƒ íƒì§€ ê²°ê³¼ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            with st.expander("íŒŒì´í”„ë¼ì¸ ë¡œê·¸"):
                                st.code(log_buffer.getvalue())
                            st.stop()
                        
                        final_csv_path = labeled_csv
                        st.success(f"âœ… ì´ìƒ íƒì§€ ì™„ë£Œ: {labeled_csv.name}")
                    except Exception as exc:
                        logs = log_buffer.getvalue()
                        st.error(f"âŒ ì´ìƒ íƒì§€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {exc}")
                        with st.expander("ìƒì„¸ ì˜¤ë¥˜"):
                            import traceback
                            st.code(logs + "\n" + traceback.format_exc())
                        st.stop()
                
                # 3ë‹¨ê³„: FAISS ì¸ë±ìŠ¤ ë¹Œë“œ
                temp_index_dir = Path(tempfile.gettempdir()) / "lorin_custom_index"
                if temp_index_dir.exists():
                    shutil.rmtree(temp_index_dir)
                
                with st.spinner("ğŸ”¨ FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì¤‘..."):
                    # CSV íŒŒì¼ì„ ì½ì–´ì„œ DataFrameìœ¼ë¡œ ë³€í™˜
                    df = pd.read_csv(final_csv_path, dtype={"EventId": str})
                    
                    # FAISS ì¸ë±ìŠ¤ ë¹Œë“œ
                    index_path = build_faiss_from_df(df, temp_index_dir)
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                if index_path:
                    st.session_state.custom_index_path = index_path
                    st.session_state.uploaded_csv_path = str(final_csv_path)
                    
                    # ìºì‹œ ì´ˆê¸°í™”í•´ì„œ ìƒˆ ì¸ë±ìŠ¤ ì‚¬ìš©
                    st.cache_resource.clear()
                    
                    st.success("âœ… ì¸ë±ìŠ¤ ì ìš© ì™„ë£Œ! í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤...")
                    st.rerun()
                else:
                    st.error("âŒ ì¸ë±ìŠ¤ ë¹Œë“œ ì‹¤íŒ¨")

            except Exception as e:
                st.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                import traceback
                with st.expander("ìƒì„¸ ì˜¤ë¥˜"):
                    st.code(traceback.format_exc())

    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ (ê°„ì†Œí™”)
    st.divider()
    if st.session_state.system_initialized:
        st.success("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
        st.caption(f"ì¸ë±ìŠ¤: `{Path(st.session_state.custom_index_path).name}`")

        if st.button("ğŸ”„ ìƒˆ TXT íŒŒì¼ ì—…ë¡œë“œ"):
            st.session_state.custom_index_path = None
            st.session_state.system_initialized = False
            st.session_state.uploaded_csv_path = None
            st.cache_resource.clear()
            st.rerun()

    # LLM ì •ë³´ (ì´ˆê¸°í™”ëœ ê²½ìš°ì—ë§Œ)
    if chatbot:
        st.divider()
        st.info(f"""
        **LLM ì •ë³´**
        - Provider: {chatbot.provider.value}
        - Model: {chatbot.model}
        """)

    # ì‹¤í—˜ ì„¤ì • (ì„ íƒì‚¬í•­)
    st.divider()
    with st.expander("ğŸ”¬ ì‹¤í—˜ ì„¤ì •"):
        experiment_mode = st.selectbox(
            "ë¶„ì„ ëª¨ë“œ",
            [
                "Full LORIN",
                "w/o Replanner",
                "w/o Evaluator",
                "Custom"
            ]
        )

        if experiment_mode == "Full LORIN":
            config = {
                "skip_planner": False,
                "skip_quality_evaluator": False,
                "skip_replanner": False
            }
            st.info("âœ… ëª¨ë“  ì»´í¬ë„ŒíŠ¸ í™œì„±í™”")

        elif experiment_mode == "w/o Replanner":
            config = {
                "skip_planner": False,
                "skip_quality_evaluator": False,
                "skip_replanner": True
            }
            st.info("âœ… Replanner ì œì™¸")

        elif experiment_mode == "w/o Evaluator":
            config = {
                "skip_planner": False,
                "skip_quality_evaluator": True,
                "skip_replanner": True
            }
            st.info("âœ… Evaluator, Replanner ì œì™¸")

        else:  # Custom
            skip_planner = st.checkbox("Planner ë¹„í™œì„±í™”", value=False)
            skip_evaluator = st.checkbox("Quality Evaluator ë¹„í™œì„±í™”", value=False)
            skip_replanner = st.checkbox("Replanner ë¹„í™œì„±í™”", value=False)

            config = {
                "skip_planner": skip_planner,
                "skip_quality_evaluator": skip_evaluator,
                "skip_replanner": skip_replanner
            }

            # í™œì„±í™”ëœ ì»´í¬ë„ŒíŠ¸ í‘œì‹œ
            active = []
            if not skip_planner:
                active.append("Planner")
            active.append("Retriever")
            if not skip_evaluator:
                active.append("Evaluator")
            if not skip_replanner:
                active.append("Replanner")

            st.caption(f"í™œì„± ì»´í¬ë„ŒíŠ¸: {' â†’ '.join(active)}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "question_input" not in st.session_state:
    st.session_state.question_input = ""
if "clear_input" not in st.session_state:
    st.session_state.clear_input = False

# ë©”ì¸ ì˜ì—­
if not st.session_state.system_initialized:
    # ì‹œìŠ¤í…œ ë¯¸ì´ˆê¸°í™” ì‹œ ì•ˆë‚´ ë©”ì‹œì§€
    st.warning("âš ï¸ TXT ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  FAISS ì¸ë±ìŠ¤ë¥¼ ë¹Œë“œí•œ í›„ ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ TXT ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

st.subheader("ğŸ“ ì§ˆë¬¸ ì…ë ¥")

# ì˜ˆì œ ì§ˆë¬¸
examples = [
    "The data passed between processes is too large and this is causing a failure. Please tell me which log range I should check for debugging.",
    "When does the Android system boot process start the DropBoxManager service?",
    "í”„ë¡œì„¸ìŠ¤ ê°„ ë°ì´í„° ì „ë‹¬ì´ ë„ˆë¬´ ì»¤ì„œ ì‹¤íŒ¨ê°€ ë°œìƒí•©ë‹ˆë‹¤. ë””ë²„ê¹…ì„ ìœ„í•´ ì–´ëŠ ë¡œê·¸ ë²”ìœ„ë¥¼ í™•ì¸í•´ì•¼ í•˜ë‚˜ìš”?"
]

selected_example = st.selectbox(
    "ì˜ˆì œ ì§ˆë¬¸ ì„ íƒ (ì„ íƒì‚¬í•­)",
    ["ì§ì ‘ ì…ë ¥"] + examples,
    key="example_selector"
)

# ì…ë ¥ ì¹¸ ì´ˆê¸°í™” ë¡œì§
if st.session_state.clear_input:
    st.session_state.question_input = ""
    st.session_state.clear_input = False

if selected_example == "ì§ì ‘ ì…ë ¥":
    question_input = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        value=st.session_state.question_input,
        height=150,
        placeholder="ë¡œê·¸ ë¶„ì„ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
        key="question_area"
    )
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°’ì„ session_stateì— ì €ì¥
    st.session_state.question_input = question_input
    question = question_input
else:
    question = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        value=selected_example,
        height=150,
        key="question_area_example"
    )

analyze_button = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

# ê²°ê³¼ ì˜ì—­
st.divider()
result_container = st.container()

# ë¶„ì„ ì‹¤í–‰
if analyze_button and question:
    # ë¶„ì„ ì‹œì‘ ì‹œ ì…ë ¥ ì¹¸ ì´ˆê¸°í™” í”Œë˜ê·¸ ì„¤ì •
    st.session_state.clear_input = True

    with st.spinner("ğŸ” ë¶„ì„ ì‹¤í–‰ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!"):
        try:
            # State ìƒì„±
            metadata = {
                "experiment_config": config
            }
            state = create_initial_state(question, metadata=metadata)

            # ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì‹¤í–‰
            async def run_analysis():
                async for event in compiled_graph.astream_events(state, version="v2"):
                    # ì§„í–‰ ìƒí™© í‘œì‹œ ì—†ì´ ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬
                    pass

                # ìµœì¢… state ë°˜í™˜
                final_state = await compiled_graph.ainvoke(state)
                return final_state

            # ë¶„ì„ ì‹¤í–‰
            final_state = asyncio.run(run_analysis())

            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (CUDA out of memory ë°©ì§€)
            try:
                import torch
                import gc

                if torch.cuda.is_available():
                    # PyTorch GPU ìºì‹œ ì •ë¦¬
                    torch.cuda.empty_cache()
                    # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                    gc.collect()

                    # ë©”ëª¨ë¦¬ ì •ë¦¬ ë¡œê·¸
                    allocated = torch.cuda.memory_allocated() / (1024 ** 3)  # GB
                    reserved = torch.cuda.memory_reserved() / (1024 ** 3)    # GB
                    st.info(f"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (í• ë‹¹: {allocated:.2f}GB, ì˜ˆì•½: {reserved:.2f}GB)")
            except Exception as cleanup_error:
                st.warning(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘ ê²½ê³ : {cleanup_error}")

            # ìµœì¢… ë‹µë³€ í‘œì‹œ
            last_message = get_last_message(final_state)

            with result_container:
                st.success("âœ¨ ë¶„ì„ ì™„ë£Œ!")

                # ğŸ“ [NEW] ë¡œê·¸ ë²”ìœ„ ì‹œê°í™” (experiment_output ìˆëŠ” ê²½ìš°)
                experiment_output = final_state.get("experiment_output")
                if experiment_output and experiment_output.get("total_log_range"):
                    st.subheader("ğŸ“ Log Range Overview")

                    total_range = experiment_output["total_log_range"]
                    rec_range = experiment_output.get("recommended_range")

                    col_range1, col_range2, col_range3 = st.columns([2, 2, 1])

                    with col_range1:
                        st.metric(
                            "ğŸ—‚ï¸ Total Log Range",
                            f"Lines {total_range['start']:,} ~ {total_range['end']:,}",
                            delta=f"{total_range['count']:,} lines total"
                        )

                    with col_range2:
                        if rec_range:
                            st.metric(
                                "ğŸ”´ Recommended Focus Range",
                                f"Lines {rec_range['start']:,} ~ {rec_range['end']:,}",
                                delta=f"{rec_range['count']:,} lines ({rec_range['coverage']})"
                            )
                        else:
                            st.metric("ğŸ”´ Recommended Focus Range", "Not specified", delta="0 lines")

                    with col_range3:
                        st.metric(
                            "ğŸ“Š Retrieved",
                            f"{total_range['retrieved_lines']:,}",
                            delta=total_range['retrieved_coverage']
                        )

                    # ì‹œê°í™”: Progress barë¡œ ì „ì²´ ë²”ìœ„ ë‚´ ì¶”ì²œ ë²”ìœ„ í‘œì‹œ
                    if rec_range:
                        st.markdown("#### ğŸ“Š Visual Log Range Map")

                        # ì „ì²´ ë²”ìœ„ ëŒ€ë¹„ ì¶”ì²œ ë²”ìœ„ì˜ ìœ„ì¹˜ ê³„ì‚°
                        total_start = total_range['start']
                        total_end = total_range['end']
                        total_span = total_end - total_start

                        rec_start = rec_range['start']
                        rec_end = rec_range['end']

                        # ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚° (0.0 ~ 1.0)
                        if total_span > 0:
                            before_ratio = (rec_start - total_start) / total_span
                            focus_ratio = (rec_end - rec_start) / total_span
                            after_ratio = (total_end - rec_end) / total_span
                        else:
                            before_ratio = 0.0
                            focus_ratio = 1.0
                            after_ratio = 0.0

                        # HTML/CSSë¥¼ ì‚¬ìš©í•œ ì»¤ìŠ¤í…€ ì‹œê°í™”
                        st.markdown(f"""
                        <div style="background: linear-gradient(to right,
                            #e0e0e0 0%,
                            #e0e0e0 {before_ratio*100}%,
                            #ff4444 {before_ratio*100}%,
                            #ff4444 {(before_ratio+focus_ratio)*100}%,
                            #e0e0e0 {(before_ratio+focus_ratio)*100}%,
                            #e0e0e0 100%);
                            height: 40px;
                            border-radius: 10px;
                            border: 2px solid #333;
                            position: relative;
                            margin: 10px 0;">
                            <div style="position: absolute; left: {before_ratio*100}%; top: -25px; font-size: 12px; font-weight: bold;">
                                â¬‡ï¸ {rec_start:,}
                            </div>
                            <div style="position: absolute; left: {(before_ratio+focus_ratio)*100}%; top: -25px; font-size: 12px; font-weight: bold;">
                                {rec_end:,} â¬‡ï¸
                            </div>
                            <div style="position: absolute; left: 50%; top: 10px; transform: translateX(-50%); color: white; font-weight: bold; font-size: 14px;">
                                ğŸ”´ Focus: {rec_range['count']:,} lines
                            </div>
                        </div>
                        <div style="display: flex; justify-content: space-between; margin-top: 5px; font-size: 12px; color: #666;">
                            <span>Start: {total_start:,}</span>
                            <span>End: {total_end:,}</span>
                        </div>
                        """, unsafe_allow_html=True)

                        # ê°œë³„ ë²”ìœ„ ì •ë³´ (ì—¬ëŸ¬ ë²”ìœ„ê°€ ìˆëŠ” ê²½ìš°)
                        old_format_ranges = experiment_output.get('ranges', [])
                        if len(old_format_ranges) > 1:
                            with st.expander(f"ğŸ“‹ Detailed Ranges ({len(old_format_ranges)} segments)"):
                                for i, (start, end) in enumerate(old_format_ranges, 1):
                                    st.text(f"  Range {i}: lines {start:,} ~ {end:,} ({end-start+1:,} lines)")

                    st.divider()

                # ìµœì¢… ë‹µë³€ (í•˜ì´ë¼ì´íŒ… ì ìš©)
                st.subheader("ğŸ“‹ ìµœì¢… ë‹µë³€")

                # [NEW] ë¡œê·¸ ë¼ì¸ ë²”ìœ„ í•˜ì´ë¼ì´íŒ… í•¨ìˆ˜
                def highlight_log_ranges(text):
                    """ë¡œê·¸ ë¼ì¸ ë²”ìœ„ë¥¼ ë³¼ë“œì²´ì™€ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ê°•ì¡°"""
                    import re

                    # íŒ¨í„´ë“¤
                    patterns = [
                        (r'(line\[\d+~\d+\])', r'**ğŸ”´ \1**'),  # line[100~200]
                        (r'(lines?\s+\d+\s*[-~]\s*\d+)', r'**ğŸ”´ \1**'),  # line 100-200
                        (r'(\[\d+\s*[-~]\s*\d+\])', r'**ğŸ”´ \1**'),  # [100-200]
                        (r'(\d+\s*[-~]\s*\d+\s+lines?)', r'**ğŸ”´ \1**'),  # 100-200 lines
                    ]

                    highlighted = text
                    for pattern, replacement in patterns:
                        highlighted = re.sub(pattern, replacement, highlighted, flags=re.IGNORECASE)

                    return highlighted

                # í•˜ì´ë¼ì´íŒ… ì ìš©ëœ ë‹µë³€ í‘œì‹œ
                highlighted_answer = highlight_log_ranges(last_message.content)
                st.markdown(highlighted_answer)

                # ğŸ“¥ [NEW] CSV ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ (ì¶”ì²œ ë¼ì¸ í‘œì‹œ)
                st.divider()

                # ë””ë²„ê¹…: ìƒíƒœ í™•ì¸
                csv_path_exists = st.session_state.uploaded_csv_path is not None
                exp_output_exists = experiment_output is not None

                # [DEBUG] ìƒíƒœ í‘œì‹œ (ê°œë°œìš©)
                with st.expander("ğŸ” [DEBUG] CSV ë‹¤ìš´ë¡œë“œ ìƒíƒœ í™•ì¸"):
                    st.write(f"CSV ê²½ë¡œ ì¡´ì¬: {csv_path_exists}")
                    st.write(f"experiment_output ì¡´ì¬: {exp_output_exists}")
                    if exp_output_exists:
                        st.write(f"experiment_output keys: {list(experiment_output.keys())}")
                        st.write(f"recommended_lines ê°œìˆ˜: {len(experiment_output.get('recommended_lines', []))}")

                if csv_path_exists and exp_output_exists:
                    st.subheader("ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ")

                    try:
                        import pandas as pd
                        from io import BytesIO

                        # ì›ë³¸ CSV ë¡œë“œ
                        original_df = pd.read_csv(st.session_state.uploaded_csv_path)

                        # LineId ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒì„±
                        if 'LineId' not in original_df.columns:
                            original_df.insert(0, 'LineId', range(1, len(original_df) + 1))

                        # ì¶”ì²œ ë¼ì¸ ì •ë³´ ì¶”ì¶œ
                        rec_range = experiment_output.get("recommended_range")
                        recommended_lines_set = set(experiment_output.get("recommended_lines", []))

                        # ìƒˆ ì»¬ëŸ¼ ì¶”ê°€: is_recommended (ì¶”ì²œ ë¼ì¸ ì—¬ë¶€)
                        if rec_range:
                            rec_start = rec_range['start']
                            rec_end = rec_range['end']

                            # ë°©ë²• 1: ë²”ìœ„ ê¸°ë°˜
                            original_df['â­_recommended'] = original_df['LineId'].apply(
                                lambda x: 'âœ“' if rec_start <= x <= rec_end else ''
                            )

                            # ë°©ë²• 2: ê°œë³„ ë¼ì¸ ê¸°ë°˜ (ë” ì •í™•)
                            if recommended_lines_set:
                                original_df['â­_recommended'] = original_df['LineId'].apply(
                                    lambda x: 'âœ“' if x in recommended_lines_set else ''
                                )
                        else:
                            original_df['â­_recommended'] = ''

                        # CSVë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
                        csv_buffer = BytesIO()
                        original_df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                        csv_bytes = csv_buffer.getvalue()

                        # í†µê³„ í‘œì‹œ
                        col_dl1, col_dl2, col_dl3 = st.columns([2, 2, 1])

                        with col_dl1:
                            st.metric("ì „ì²´ ë¡œê·¸ ë¼ì¸ ìˆ˜", f"{len(original_df):,}")

                        with col_dl2:
                            recommended_count = (original_df['â­_recommended'] == 'âœ“').sum()
                            st.metric("ì¶”ì²œ ë¼ì¸ ìˆ˜", f"{recommended_count:,}",
                                     delta=f"{recommended_count/len(original_df)*100:.1f}%")

                        with col_dl3:
                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            st.download_button(
                                label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                                data=csv_bytes,
                                file_name=f"analysis_result_{Path(st.session_state.uploaded_csv_path).stem}.csv",
                                mime="text/csv",
                                help="ì¶”ì²œ ë¼ì¸ì´ 'â­_recommended' ì»¬ëŸ¼ì— âœ“ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤."
                            )

                        # ì „ì²´ ë¡œê·¸ ë¯¸ë¦¬ë³´ê¸° (ê¶Œì¥ ë²”ìœ„ í•˜ì´ë¼ì´íŠ¸)
                        st.subheader("ğŸ“„ ì „ì²´ ë¡œê·¸ ë¼ì¸ (ê¶Œì¥ ë²”ìœ„ í•˜ì´ë¼ì´íŠ¸)")
                        st.caption(f"ì´ {len(original_df):,}í–‰ ì „ì²´ í‘œì‹œ")

                        if 'â­_recommended' in original_df.columns:
                            def highlight_rows(row):
                                color = '#ffe5e5' if row['â­_recommended'] == 'âœ“' else ''
                                return ['background-color: {}'.format(color) if color else '' for _ in row]

                            styled_preview = original_df.style.apply(highlight_rows, axis=1)
                            st.dataframe(styled_preview, use_container_width=True, height=600)
                            st.caption("ğŸ”´ ë¶‰ê²Œ í‘œì‹œëœ í–‰ì´ ê¶Œì¥ ë¡œê·¸ ë²”ìœ„ì— ì†í•œ ë¼ì¸ì…ë‹ˆë‹¤.")
                        else:
                            st.dataframe(original_df, use_container_width=True, height=600)
                            st.caption("ê¶Œì¥ ë²”ìœ„ ì •ë³´ê°€ ì—†ì–´ ì¼ë°˜ í…Œì´ë¸”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")

                    except Exception as csv_error:
                        st.error(f"CSV ìƒì„± ì‹¤íŒ¨: {csv_error}")
                        with st.expander("CSV ì˜¤ë¥˜ ìƒì„¸"):
                            import traceback
                            st.code(traceback.format_exc())
                else:
                    # ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•Šì„ ë•Œ
                    if not csv_path_exists:
                        st.info("â„¹ï¸ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV ë‹¤ìš´ë¡œë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                    elif not exp_output_exists:
                        st.warning("âš ï¸ experiment_outputì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. answer.pyê°€ ìµœì‹  ë²„ì „ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")

                # ì‹œê°í™” ìë£Œ (CSVê°€ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ)
                if st.session_state.uploaded_csv_path:
                    st.divider()
                    with st.expander("ğŸ“ˆ ì‹œê°í™” ìë£Œ ë³´ê¸°", expanded=False):
                        try:
                            with st.spinner("ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘... ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ê³  ìˆì–´ìš”!"):
                                viz_path = create_visualization(st.session_state.uploaded_csv_path)

                                if Path(viz_path).exists():
                                    st.image(viz_path, use_container_width=True)
                                    st.caption("ë¡œê·¸ ë°ì´í„° ì¢…í•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
                                else:
                                    st.warning("ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                        except Exception as viz_error:
                            st.error(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {viz_error}")
                            with st.expander("ì‹œê°í™” ì˜¤ë¥˜ ìƒì„¸"):
                                import traceback
                                st.code(traceback.format_exc())

                # ë©”íƒ€ë°ì´í„°
                with st.expander("ğŸ“Š ë¶„ì„ ë©”íƒ€ë°ì´í„°"):
                    metadata = final_state.get("metadata", {})

                    col_m1, col_m2, col_m3 = st.columns(3)
                    with col_m1:
                        st.metric("FAISS í˜¸ì¶œ", metadata.get("faiss_calls", 0))
                    with col_m2:
                        st.metric("Planner ë°˜ë³µ", metadata.get("planner_iterations", 0))
                    with col_m3:
                        st.metric("ì´ ë©”ì‹œì§€", len(final_state.get("messages", [])))

                    st.json(metadata)

                # ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬
                with st.expander("ğŸ’¬ ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬"):
                    for i, msg in enumerate(final_state.get("messages", []), 1):
                        ak = getattr(msg, "additional_kwargs", {}) or getattr(msg, "kwargs", {}) or {}
                        agent_name = ak.get("agent_name", "unknown")

                        st.text(f"[{i}] {msg.__class__.__name__} from {agent_name}")
                        st.code(msg.content, language="text")

        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                import traceback
                st.code(traceback.format_exc())

# Footer
st.divider()
st.caption("LORIN Log Analyzer v1.0 - ë¡œì»¬í˜¸ìŠ¤íŠ¸ ë²„ì „")
